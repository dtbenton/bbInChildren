I've chosen not to include the base rate stuff in the intro because it's not necessarily the focus of this study -- the point of the study is to look at how children reason about BB events for 3 and 4 objects and whether their inferences comport with the predictions of a bayes model or an associative model. By including a discussion of base rates (at least in the intro), we're setting ourselves up to be swiftly rejected. I can see a reveiwer saying, "Ok, you talked all about base rates, but your study doesn't actually manipulate base rates. Now go to that study." I'm under a time crunch, and as much as I'd like to collect those data, cannot. I'm fine mentioning this work as one limitations and allude to how future research should investigate it, but I don't think the place to do it is in the inro.

# starrt email with this:

I kept most of the text because it does strengthen the paper

Analysis

I see your point about the linear model but remember that even if, for a given child, the response is binary, averaged over children the response is actually continuous. because we're reporting averages (on continuous values) a linear model is perfectly fine. Now, what I'm happy to do is make a note the the conclusions of the study don't change if we run these a logistic models. (which, if memory served, they don't, but i can run those again to be sure).

i don't think we should remove participants who said yes to everything for two reasons. first, power. second, all yes is actually meaningful and reflects uncertainy (when considered over participants)

I've kept in this text: If such a model was able to capture the present behavioral data, then the conclusion that the Rescorla-Wagner model is insufficient to explain childrenâ€™s causal reasoning (e.g., Sobel et al., 2004) may be premature  (we return to this issue in the General Discussion). I disagree that I'm not being constructive. The point here is look: This is what has been said but it turns out that when you increase hte number of objects (by as little as 1), the RW does a much better job. It is important that the literature sees that there's nuance to this point, and ignoring it is, in my view, painting an inaccurate picture (because the only statement out there would be yours in S 2004). And I even disagree with the point of S 2004. Yes it was to build a B model, but you also go to great lengths to knock down Rescorla. I'm rectifying situations by saying loook RW isn't all that bad. It's not like I'm saying S 2004 is wrong and his conclusions are bunk. I'm simply adding (much needed) nuance. 

you say to remove baeys model of 1. we have no basis to remove it for two reasons. first, we did not manipulate base rates. secondly, it wasn't, as your suggestion would seem to predict, the worst performning model.

send david model data to compute rmse's

you seem to suggest throughout that i'm assuming that there is one model and even say so in one of your comments. i disagree that saying that participants mostly rely on mechanism A and some on mechanism B is saying that only A wins. I'm expliclty saying its both, and i go on in the GD to acknowledge that the balance may not always be this way. we may just have to disagree about this point. 